{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select \n",
    "from selenium.webdriver.support import expected_conditions as EC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit 537.36 (KHTML, like Gecko) Chrome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/Users/daesikkim/Downloads/chromedriver', chrome_options=options)\n",
    "driver.implicitly_wait(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more candidate!\n"
     ]
    }
   ],
   "source": [
    "# ecost.nec.go.kr 사이트 가져오기     \n",
    "dict_candidate_seoul = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(0, 5): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('1100') #서울특별시\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_seoul['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_seoul['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_seoul['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_seoul['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_seoul['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_seoul['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_seoul['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_seoul['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_seoul['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_seoul['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_seoul = pd.DataFrame(dict_candidate_seoul)\n",
    "writer = pd.ExcelWriter('df_candidate_seoul.xlsx')\n",
    "df_candidate_seoul.to_excel(writer, 'seoul')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more candidate!\n"
     ]
    }
   ],
   "source": [
    "# ecost.nec.go.kr 사이트 가져오기     \n",
    "dict_candidate_busan = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(0, 10): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('2600') #부산\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_busan['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_busan['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_busan['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_busan['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_busan['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_busan['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_busan['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_busan['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_busan['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_busan['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_busan = pd.DataFrame(dict_candidate_busan)\n",
    "writer = pd.ExcelWriter('df_candidate_busan.xlsx')\n",
    "df_candidate_busan.to_excel(writer, 'busan')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more candidate!\n"
     ]
    }
   ],
   "source": [
    "# ecost.nec.go.kr 사이트 가져오기     \n",
    "dict_candidate_ich = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(0, 10): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('2800') #인천\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_ich['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_ich['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_ich['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_ich['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_ich['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_ich['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_ich['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_ich['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_ich['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_ich['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_ich = pd.DataFrame(dict_candidate_ich)\n",
    "writer = pd.ExcelWriter('df_candidate_ich.xlsx')\n",
    "df_candidate_ich.to_excel(writer, 'ich')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more candidate!\n"
     ]
    }
   ],
   "source": [
    "# ecost.nec.go.kr 사이트 가져오기     \n",
    "dict_candidate_dj = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(0, 20): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('3000') #대전\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_dj['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_dj['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_dj['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_dj['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_dj['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_dj['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_dj['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_dj['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_dj['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_dj['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_dj = pd.DataFrame(dict_candidate_dj)\n",
    "writer = pd.ExcelWriter('df_candidate_dj.xlsx')\n",
    "df_candidate_dj.to_excel(writer, 'dj')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more candidate!\n"
     ]
    }
   ],
   "source": [
    "# ecost.nec.go.kr 사이트 가져오기     \n",
    "dict_candidate_gg = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(0, 5): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('4100') #경기\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_gg['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_gg['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_gg['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_gg['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_gg['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_gg['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_gg['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_gg['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_gg['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_gg['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_gg = pd.DataFrame(dict_candidate_gg)\n",
    "writer = pd.ExcelWriter('df_candidate_gg.xlsx')\n",
    "df_candidate_gg.to_excel(writer, 'gg')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more candidate!\n"
     ]
    }
   ],
   "source": [
    "# ecost.nec.go.kr 사이트 가져오기     \n",
    "dict_candidate_gw = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(0, 25): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('4200') #경기\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_gw['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_gw['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_gw['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_gw['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_gw['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_gw['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_gw['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_gw['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_gw['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_gw['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_gw = pd.DataFrame(dict_candidate_gw)\n",
    "writer = pd.ExcelWriter('df_candidate_gw.xlsx')\n",
    "df_candidate_gw.to_excel(writer, 'gw')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more candidate!\n"
     ]
    }
   ],
   "source": [
    "dict_candidate_chn = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(0, 15): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('4400') #충남\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_chn['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_chn['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_chn['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_chn['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_chn['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_chn['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_chn['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_chn['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_chn['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_chn['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_chn = pd.DataFrame(dict_candidate_chn)\n",
    "writer = pd.ExcelWriter('df_candidate_chn.xlsx')\n",
    "df_candidate_chn.to_excel(writer, 'chn')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more candidate!\n"
     ]
    }
   ],
   "source": [
    "dict_candidate_jb = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(0, 10): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('4500') #jeonbuk\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_jb['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_jb['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_jb['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_jb['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_jb['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_jb['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_jb['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_jb['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_jb['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_jb['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_jb = pd.DataFrame(dict_candidate_jb)\n",
    "writer = pd.ExcelWriter('df_candidate_jb.xlsx')\n",
    "df_candidate_jb.to_excel(writer, 'jb')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more candidate!\n"
     ]
    }
   ],
   "source": [
    "dict_candidate_kn = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(0, 10): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('4800') #경남\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_kn['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_kn['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_kn['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_kn['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_kn['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_kn['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_kn['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_kn['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_kn['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_kn['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_kn = pd.DataFrame(dict_candidate_kn)\n",
    "writer = pd.ExcelWriter('df_candidate_kn.xlsx')\n",
    "df_candidate_kn.to_excel(writer, 'kn')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n"
     ]
    }
   ],
   "source": [
    "dict_candidate_dg = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(0, 25): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('2700') #대구\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_dg['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_dg['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_dg['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_dg['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_dg['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_dg['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_dg['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_dg['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_dg['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_dg['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_dg = pd.DataFrame(dict_candidate_dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n"
     ]
    }
   ],
   "source": [
    "dict_candidate_dg = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(25, 50): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('2700') #대구\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_dg['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_dg['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_dg['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_dg['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_dg['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_dg['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_dg['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_dg['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_dg['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_dg['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_dg = df_candidate_dg.append(pd.DataFrame(dict_candidate_dg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n"
     ]
    }
   ],
   "source": [
    "dict_candidate_dg = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(50, 75): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('2700') #대구\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_dg['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_dg['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_dg['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_dg['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_dg['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_dg['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_dg['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_dg['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_dg['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_dg['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_dg = df_candidate_dg.append(pd.DataFrame(dict_candidate_dg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more candidate!\n"
     ]
    }
   ],
   "source": [
    "dict_candidate_dg = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(75, 100): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('2700') #대구\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_dg['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_dg['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_dg['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_dg['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_dg['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_dg['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_dg['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_dg['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_dg['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_dg['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_dg = df_candidate_dg.append(pd.DataFrame(dict_candidate_dg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('df_candidate_dg.xlsx')\n",
    "df_candidate_dg.to_excel(writer, 'dg')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n"
     ]
    }
   ],
   "source": [
    "dict_candidate_chb = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(0, 25): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('4300') #chb\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_chb['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_chb['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_chb['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_chb['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_chb['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_chb['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_chb['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_chb['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_chb['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_chb['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_chb = pd.DataFrame(dict_candidate_chb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n"
     ]
    }
   ],
   "source": [
    "dict_candidate_chb = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(25, 50): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('4300') #chb\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_chb['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_chb['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_chb['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_chb['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_chb['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_chb['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_chb['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_chb['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_chb['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_chb['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_chb = df_candidate_chb.append(pd.DataFrame(dict_candidate_chb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n"
     ]
    }
   ],
   "source": [
    "dict_candidate_chb = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(50, 75): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('4300') #chb\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_chb['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_chb['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_chb['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_chb['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_chb['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_chb['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_chb['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_chb['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_chb['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_chb['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_chb = df_candidate_chb.append(pd.DataFrame(dict_candidate_chb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more candidate!\n"
     ]
    }
   ],
   "source": [
    "dict_candidate_chb = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(75, 77): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('4300') #chb\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_chb['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_chb['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_chb['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_chb['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_chb['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_chb['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_chb['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_chb['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_chb['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_chb['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_chb = df_candidate_chb.append(pd.DataFrame(dict_candidate_chb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('df_candidate_chb.xlsx')\n",
    "df_candidate_chb.to_excel(writer, 'chb')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n"
     ]
    }
   ],
   "source": [
    "dict_candidate_jn = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(0, 25): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('4600') #jn\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_jn['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_jn['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_jn['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_jn['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_jn['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_jn['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_jn['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_jn['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_jn['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_jn['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_jn = pd.DataFrame(dict_candidate_jn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more candidate!\n"
     ]
    }
   ],
   "source": [
    "dict_candidate_jn = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(25, 50): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('4600') #jn\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_jn['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_jn['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_jn['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_jn['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_jn['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_jn['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_jn['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_jn['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_jn['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_jn['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_jn = df_candidate_jn.append(pd.DataFrame(dict_candidate_jn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('df_candidate_jn.xlsx')\n",
    "df_candidate_jn.to_excel(writer, 'jn')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n",
      "No more page!\n"
     ]
    }
   ],
   "source": [
    "dict_candidate_kb = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(0, 25): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('4700') #kb\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_kb['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_kb['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_kb['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_kb['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_kb['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_kb['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_kb['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_kb['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_kb['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_kb['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_kb = pd.DataFrame(dict_candidate_jn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more page!\n",
      "No more page!\n",
      "No more candidate!\n"
     ]
    }
   ],
   "source": [
    "dict_candidate_kb = {'date': [], 'name': [], 'acct': [], 'category': [], 'item': [], 'amount': [], 'dest': [], 'address': [], 'job': [], 'phone': []}\n",
    "for p in range(25, 50): \n",
    "    try: \n",
    "        driver.get('http://ecost.nec.go.kr/cfos.do')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.find_element_by_css_selector('#mNaviImg05').click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        select1 = Select(driver.find_element_by_name('SG_ID'))\n",
    "        select1.select_by_value('620180613')\n",
    "        select2 = Select(driver.find_element_by_name('rg'))\n",
    "        select2.select_by_value('4700') #kb\n",
    "        driver.find_element_by_css_selector('#btn_search > img').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)')))\n",
    "        driver.find_element_by_css_selector(f'#content > table.table_detail01 > tbody > tr:nth-of-type({p+1}) > td:nth-of-type(4)').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        for page in range(0, 49):\n",
    "            try:\n",
    "                driver.implicitly_wait(2)\n",
    "                page_button = driver.find_element_by_css_selector(f'#paging > span > span:nth-of-type({page+1}) > a')\n",
    "                time.sleep(1)\n",
    "                page_button.click()\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                for line in range(0, 9):\n",
    "                    if soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td') != []:\n",
    "                        dict_candidate_kb['date'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[0].string)\n",
    "                        dict_candidate_kb['name'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[1].string)\n",
    "                        dict_candidate_kb['acct'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[2].string.replace(' ', ''))\n",
    "                        dict_candidate_kb['category'].append(str(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[3]).replace('<br/>', '').replace('\\n', '').replace('\\t','').replace('</td>', '').replace(' ','').split('\">')[1])\n",
    "                        dict_candidate_kb['item'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[4].string)\n",
    "                        dict_candidate_kb['amount'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[5].string)\n",
    "                        dict_candidate_kb['dest'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[6].string)\n",
    "                        dict_candidate_kb['address'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[7].string)\n",
    "                        dict_candidate_kb['job'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[8].string)\n",
    "                        dict_candidate_kb['phone'].append(soup.select(f'#content > table.table_detail01 > tbody > tr:nth-of-type({line+1}) > td')[9].string)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('No more page!')\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print('No more candidate!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:BigBull]",
   "language": "python",
   "name": "conda-env-BigBull-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
